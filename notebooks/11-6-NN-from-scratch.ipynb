{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Network Pipeline for problem from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the neural network structure here: https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models\n",
    "\n",
    "and applying to our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Concatenate, SpatialDropout1D, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from datatasks.sample_data import sample_data\n",
    "\n",
    "from datatasks.new_preprocess import tokenize\n",
    "\n",
    "from models.models import evaluate_model\n",
    "\n",
    "from models.plot import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "DATA_INTERIM_PATH = DATA_PATH + 'interim/'\n",
    "train = pd.read_csv(DATA_INTERIM_PATH + 'train_p.csv')\n",
    "val = pd.read_csv(DATA_INTERIM_PATH + 'val_p.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = sample_data(train, 50000, 'train')\n",
    "val_s = sample_data(val, 10000, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>published-at</th>\n",
       "      <th>title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>external_links</th>\n",
       "      <th>internal_links</th>\n",
       "      <th>hyperpartisan</th>\n",
       "      <th>bias</th>\n",
       "      <th>url</th>\n",
       "      <th>labeled-by</th>\n",
       "      <th>HP_links_count</th>\n",
       "      <th>nonHP_links_count</th>\n",
       "      <th>unknown_links_count</th>\n",
       "      <th>domain</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189698</td>\n",
       "      <td>376419</td>\n",
       "      <td>2009-07-20</td>\n",
       "      <td>?Brown Bailout?? Hardly</td>\n",
       "      <td>Last month, FedEx launched a multimillion-doll...</td>\n",
       "      <td>{'http://www.reuters.com/article/companyNews/i...</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>least</td>\n",
       "      <td>https://factcheck.org/2009/07/brown-bailout-ha...</td>\n",
       "      <td>publisher</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>factcheck</td>\n",
       "      <td>Brown Bailout Hardly\\n Last month, FedEx launc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120949</td>\n",
       "      <td>233372</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>Prosecutors: Ex-surgeon calls himself 'killer'...</td>\n",
       "      <td>DALLAS (AP) ? A Texas neurosurgeon facing crim...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>least</td>\n",
       "      <td>https://apnews.com/amp/123a956665774b639465eec...</td>\n",
       "      <td>publisher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>apnews</td>\n",
       "      <td>Prosecutors: Ex-surgeon calls himself killer i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      id published-at  \\\n",
       "0  189698  376419   2009-07-20   \n",
       "1  120949  233372   2015-08-25   \n",
       "\n",
       "                                               title  \\\n",
       "0                            ?Brown Bailout?? Hardly   \n",
       "1  Prosecutors: Ex-surgeon calls himself 'killer'...   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  Last month, FedEx launched a multimillion-doll...   \n",
       "1  DALLAS (AP) ? A Texas neurosurgeon facing crim...   \n",
       "\n",
       "                                      external_links internal_links  \\\n",
       "0  {'http://www.reuters.com/article/companyNews/i...             {}   \n",
       "1                                                 {}             {}   \n",
       "\n",
       "   hyperpartisan   bias                                                url  \\\n",
       "0          False  least  https://factcheck.org/2009/07/brown-bailout-ha...   \n",
       "1          False  least  https://apnews.com/amp/123a956665774b639465eec...   \n",
       "\n",
       "  labeled-by  HP_links_count  nonHP_links_count  unknown_links_count  \\\n",
       "0  publisher               0                  4                    6   \n",
       "1  publisher               0                  0                    0   \n",
       "\n",
       "      domain                                  preprocessed_text  \n",
       "0  factcheck  Brown Bailout Hardly\\n Last month, FedEx launc...  \n",
       "1     apnews  Prosecutors: Ex-surgeon calls himself killer i...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = tokenize(train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = \"../data/external/GoogleNews-vectors-negative300.bin.gz\"\n",
    "#vectors = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 35\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT=.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_data(df, vectors):\n",
    "    \n",
    "    all_words = [word for tokens in df[\"tokens\"] for word in tokens]\n",
    "    VOCAB = sorted(list(set(all_words)))\n",
    "    VOCAB_SIZE = len(VOCAB)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "    tokenizer.fit_on_texts(df[\"preprocessed_text\"].tolist())\n",
    "    sequences = tokenizer.texts_to_sequences(df[\"preprocessed_text\"].tolist())\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    cnn_data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    labels = np.asarray(df[\"hyperpartisan\"])\n",
    "\n",
    "    indices = np.arange(cnn_data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    cnn_data = cnn_data[indices]\n",
    "    labels = labels[indices]\n",
    "    num_validation_samples = int(VALIDATION_SPLIT * cnn_data.shape[0])\n",
    "\n",
    "    embedding_weights = np.zeros((len(word_index)+1, EMBEDDING_DIM))\n",
    "    for word,index in word_index.items():\n",
    "        embedding_weights[index,:] = vectors[word] if word in vectors else np.random.rand(EMBEDDING_DIM)\n",
    "    print(embedding_weights.shape)\n",
    "    \n",
    "    return cnn_data, labels, embedding_weights, word_index, num_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 275014 unique tokens.\n",
      "(275015, 300)\n"
     ]
    }
   ],
   "source": [
    "cnn_data, labels, embedding_weights, word_index, num_validation_samples = create_cnn_data(train_s, vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_features_train = train_s[['HP_links_count']].values\n",
    "custom_features_val = val_s[['HP_links_count']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn_model(embeddings, max_sequence_length, num_words, embedding_dim, custom_features, trainable=False):\n",
    "    \n",
    "    # Main input layer for text features\n",
    "    main_input = Input(shape=(max_sequence_length,), dtype='int32', name='main_input')\n",
    "    \n",
    "    # Create embeddings\n",
    "    x = Embedding(input_dim=num_words,\n",
    "                 output_dim=embedding_dim,\n",
    "                 weights=[embeddings],\n",
    "                 input_length=max_sequence_length,\n",
    "                 trainable=trainable)(main_input)\n",
    "    \n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "    # Layers for text only features\n",
    "    #lstm_out = Bidirectional(LSTM(32, dropout=0.2))(x)\n",
    "    \n",
    "    #print(lstm_out.shape)\n",
    "    \n",
    "    convs = []\n",
    "    filter_sizes = [3,4,5]\n",
    "\n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=128, kernel_size=filter_size, activation='relu')(x)\n",
    "        l_pool = MaxPooling1D(pool_size=3)(l_conv)\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "    \n",
    "    conv_out = Dropout(0.5)(l_merge)\n",
    "    conv_out = Flatten()(conv_out)\n",
    "    \n",
    "    # Aux output for text features only\n",
    "    auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(conv_out)\n",
    "    \n",
    "    # Input layer for custom features\n",
    "    auxiliary_input = Input(shape=(custom_features.shape[1],), name='aux_input')\n",
    "    \n",
    "    # Concatenate text and custom features\n",
    "    x = keras.layers.concatenate([conv_out, auxiliary_input])\n",
    "    \n",
    "    # Dense layers using text and custom features\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # And finally we add the main logistic regression layer\n",
    "    main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', loss_weights=[1., 0.2], metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap model for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_nn_model(embedding_weights, MAX_SEQUENCE_LENGTH, len(word_index)+1, EMBEDDING_DIM, custom_features_train, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = cnn_data\n",
    "x_custom_train = custom_features_train\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49997 samples, validate on 9999 samples\n",
      "Epoch 1/30\n",
      "49997/49997 [==============================] - 45s 902us/step - loss: 0.7828 - main_output_loss: 0.6633 - aux_output_loss: 0.5972 - main_output_acc: 0.5659 - aux_output_acc: 0.6533 - val_loss: 0.8517 - val_main_output_loss: 0.7023 - val_aux_output_loss: 0.7469 - val_main_output_acc: 0.4907 - val_aux_output_acc: 0.4918\n",
      "Epoch 2/30\n",
      "49997/49997 [==============================] - 45s 898us/step - loss: 0.6639 - main_output_loss: 0.5638 - aux_output_loss: 0.5004 - main_output_acc: 0.7077 - aux_output_acc: 0.7398 - val_loss: 0.8983 - val_main_output_loss: 0.7499 - val_aux_output_loss: 0.7418 - val_main_output_acc: 0.4776 - val_aux_output_acc: 0.5270\n",
      "Epoch 3/30\n",
      "49997/49997 [==============================] - 45s 900us/step - loss: 0.6032 - main_output_loss: 0.5105 - aux_output_loss: 0.4634 - main_output_acc: 0.7488 - aux_output_acc: 0.7664 - val_loss: 0.9089 - val_main_output_loss: 0.7587 - val_aux_output_loss: 0.7513 - val_main_output_acc: 0.4877 - val_aux_output_acc: 0.5051\n",
      "Epoch 4/30\n",
      "49997/49997 [==============================] - 46s 917us/step - loss: 0.5716 - main_output_loss: 0.4832 - aux_output_loss: 0.4420 - main_output_acc: 0.7675 - aux_output_acc: 0.7821 - val_loss: 0.9150 - val_main_output_loss: 0.7654 - val_aux_output_loss: 0.7479 - val_main_output_acc: 0.4894 - val_aux_output_acc: 0.5121\n",
      "Epoch 5/30\n",
      "49997/49997 [==============================] - 47s 943us/step - loss: 0.5376 - main_output_loss: 0.4545 - aux_output_loss: 0.4150 - main_output_acc: 0.7871 - aux_output_acc: 0.8006 - val_loss: 0.9123 - val_main_output_loss: 0.7591 - val_aux_output_loss: 0.7662 - val_main_output_acc: 0.4764 - val_aux_output_acc: 0.5192\n",
      "Epoch 6/30\n",
      "49997/49997 [==============================] - 47s 941us/step - loss: 0.5108 - main_output_loss: 0.4320 - aux_output_loss: 0.3940 - main_output_acc: 0.7996 - aux_output_acc: 0.8135 - val_loss: 0.9365 - val_main_output_loss: 0.7800 - val_aux_output_loss: 0.7826 - val_main_output_acc: 0.4772 - val_aux_output_acc: 0.5114\n",
      "Epoch 7/30\n",
      "49997/49997 [==============================] - 48s 950us/step - loss: 0.4930 - main_output_loss: 0.4175 - aux_output_loss: 0.3777 - main_output_acc: 0.8103 - aux_output_acc: 0.8260 - val_loss: 0.9307 - val_main_output_loss: 0.7767 - val_aux_output_loss: 0.7700 - val_main_output_acc: 0.4902 - val_aux_output_acc: 0.5193\n",
      "Epoch 8/30\n",
      "49997/49997 [==============================] - 47s 947us/step - loss: 0.4679 - main_output_loss: 0.3959 - aux_output_loss: 0.3597 - main_output_acc: 0.8240 - aux_output_acc: 0.8355 - val_loss: 0.9664 - val_main_output_loss: 0.8074 - val_aux_output_loss: 0.7949 - val_main_output_acc: 0.4691 - val_aux_output_acc: 0.4721\n",
      "Epoch 9/30\n",
      "49997/49997 [==============================] - 46s 912us/step - loss: 0.4502 - main_output_loss: 0.3819 - aux_output_loss: 0.3414 - main_output_acc: 0.8314 - aux_output_acc: 0.8471 - val_loss: 0.9518 - val_main_output_loss: 0.7970 - val_aux_output_loss: 0.7737 - val_main_output_acc: 0.4985 - val_aux_output_acc: 0.5276\n",
      "Epoch 10/30\n",
      " 3584/49997 [=>............................] - ETA: 36s - loss: 0.4050 - main_output_loss: 0.3435 - aux_output_loss: 0.3075 - main_output_acc: 0.8521 - aux_output_acc: 0.8703"
     ]
    }
   ],
   "source": [
    "model.fit([x_train, x_custom_train], [y_train, y_train], validation_data=([t_cnn_data, custom_features_val], [t_labels, t_labels]), epochs=30, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_s = tokenize(val_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129553 unique tokens.\n",
      "(129554, 300)\n"
     ]
    }
   ],
   "source": [
    "t_cnn_data, t_labels, t_embedding_weights, t_word_index, t_num_validation_samples = create_cnn_data(val_s, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict([t_cnn_data, custom_features_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "_ = plt.hist(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [0 if preds[0][i][0] < .5 else 1 for i in range(len(preds[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.52      0.32      0.40      4999\n",
      "       True       0.51      0.70      0.59      5000\n",
      "\n",
      "avg / total       0.52      0.51      0.50      9999\n",
      "\n",
      "Accuracy: 0.5136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5135513551355135"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(preds, t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
